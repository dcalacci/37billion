{
 "metadata": {
  "name": "",
  "signature": "sha256:27dcd11e0f03f8d29ddc340d7de54e4603224d5386d60fb76f7af5826c63f73f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Setup\n",
      "\n",
      "Imports and setting data directories. \n",
      "\n",
      "You can pull this entire repository from [here](http://github.com/dcalacci/37billion) to replicate my work."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, random, shapely, fiona\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import shapely.geometry\n",
      "import utils\n",
      "\n",
      "%load_ext autoreload\n",
      "% autoreload 2\n",
      "\n",
      "data_dir = \"../data/massvehicledata/\"\n",
      "companion_data_dir = '../data/companion/Tabular/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_large_csv(csv_file, header_file):\n",
      "    \"loads csv_file using chunks/iterator. uses header_file['Field'] as colnames\"\n",
      "    tp = pd.read_csv(csv_file, iterator=True, chunksize=1000)\n",
      "    headers = pd.read_csv(header_file)\n",
      "    df = pd.concat([chunk for chunk in tp], ignore_index=True, names=headers)\n",
      "    df.columns = headers['Field']\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}